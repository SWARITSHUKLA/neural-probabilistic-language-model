{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "876667e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets build the model :)\n"
     ]
    }
   ],
   "source": [
    "print('Lets build the model :)')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#In this modeling approach we are taking 3 previous and trying to predict the 4th word in the sequance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "be210e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "141884cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "28dc6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the mappings of characters to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "4ff63d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the dataset\n",
    "block_size = 3 #context length how many characters do we take to predict the next one\n",
    "X,Y = [],[]\n",
    "for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix] #crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "483c71ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(219384384)\n",
    "#creating a lookup table for the character embeddings\n",
    "C = torch.randn((27,2), generator = g)\n",
    "# Constructiong the hidden layer\n",
    "#The number of inputs to this layer is going to be 3 * 2  because we hae to dimensional embeddings and we have 3 of them\n",
    "# and its up to us to decide how many neurons we want inside the layer here we are going with 100 of them\n",
    "W1 = torch.randn(6,100, generator = g )\n",
    "b1 = torch.randn(100, generator = g) \n",
    "W2 = torch.randn(100, 27, generator = g) #our second layer will take 100 inputs and \n",
    "b2 = torch.randn(27, generator = g)\n",
    "parameters = [C,W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "98c3cf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) #tells us number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "b3cc23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "#we do this because p.requires_grad is false by default but insted of treating these tensors as constant we want pytorch to treat them as variable, Variable which requires to have gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "a18a2d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 17.7404842376709 for iteration= 0\n",
      "loss= 17.38859748840332 for iteration= 1\n",
      "loss= 13.848173141479492 for iteration= 2\n",
      "loss= 14.321552276611328 for iteration= 3\n",
      "loss= 9.560193061828613 for iteration= 4\n",
      "loss= 15.206975936889648 for iteration= 5\n",
      "loss= 12.192161560058594 for iteration= 6\n",
      "loss= 12.558395385742188 for iteration= 7\n",
      "loss= 11.932211875915527 for iteration= 8\n",
      "loss= 13.271073341369629 for iteration= 9\n",
      "loss= 9.676918029785156 for iteration= 10\n",
      "loss= 10.957734107971191 for iteration= 11\n",
      "loss= 9.470869064331055 for iteration= 12\n",
      "loss= 10.225584030151367 for iteration= 13\n",
      "loss= 10.456774711608887 for iteration= 14\n",
      "loss= 8.826881408691406 for iteration= 15\n",
      "loss= 10.016298294067383 for iteration= 16\n",
      "loss= 8.247517585754395 for iteration= 17\n",
      "loss= 8.32795238494873 for iteration= 18\n",
      "loss= 8.87733268737793 for iteration= 19\n",
      "loss= 8.656319618225098 for iteration= 20\n",
      "loss= 9.51900863647461 for iteration= 21\n",
      "loss= 9.376317024230957 for iteration= 22\n",
      "loss= 7.886662006378174 for iteration= 23\n",
      "loss= 8.96883773803711 for iteration= 24\n",
      "loss= 8.520697593688965 for iteration= 25\n",
      "loss= 6.373957633972168 for iteration= 26\n",
      "loss= 7.29991340637207 for iteration= 27\n",
      "loss= 6.19553804397583 for iteration= 28\n",
      "loss= 8.384263038635254 for iteration= 29\n",
      "loss= 5.176566123962402 for iteration= 30\n",
      "loss= 6.290639877319336 for iteration= 31\n",
      "loss= 5.87807559967041 for iteration= 32\n",
      "loss= 4.414761066436768 for iteration= 33\n",
      "loss= 6.684024810791016 for iteration= 34\n",
      "loss= 6.5621337890625 for iteration= 35\n",
      "loss= 4.423240661621094 for iteration= 36\n",
      "loss= 4.439551830291748 for iteration= 37\n",
      "loss= 5.115361213684082 for iteration= 38\n",
      "loss= 6.179971218109131 for iteration= 39\n",
      "loss= 4.87471342086792 for iteration= 40\n",
      "loss= 5.44658088684082 for iteration= 41\n",
      "loss= 4.305734634399414 for iteration= 42\n",
      "loss= 5.812265396118164 for iteration= 43\n",
      "loss= 4.80837345123291 for iteration= 44\n",
      "loss= 5.027597427368164 for iteration= 45\n",
      "loss= 5.457340717315674 for iteration= 46\n",
      "loss= 5.030655384063721 for iteration= 47\n",
      "loss= 5.487032890319824 for iteration= 48\n",
      "loss= 4.242400646209717 for iteration= 49\n",
      "loss= 4.0636796951293945 for iteration= 50\n",
      "loss= 3.5601119995117188 for iteration= 51\n",
      "loss= 5.030806541442871 for iteration= 52\n",
      "loss= 4.303449630737305 for iteration= 53\n",
      "loss= 4.016901969909668 for iteration= 54\n",
      "loss= 5.62748384475708 for iteration= 55\n",
      "loss= 4.269900321960449 for iteration= 56\n",
      "loss= 4.45644474029541 for iteration= 57\n",
      "loss= 4.786176681518555 for iteration= 58\n",
      "loss= 4.599915504455566 for iteration= 59\n",
      "loss= 3.4271717071533203 for iteration= 60\n",
      "loss= 5.053876876831055 for iteration= 61\n",
      "loss= 4.286798000335693 for iteration= 62\n",
      "loss= 3.9361133575439453 for iteration= 63\n",
      "loss= 4.059410095214844 for iteration= 64\n",
      "loss= 4.864147186279297 for iteration= 65\n",
      "loss= 4.223952293395996 for iteration= 66\n",
      "loss= 4.696890354156494 for iteration= 67\n",
      "loss= 4.311789512634277 for iteration= 68\n",
      "loss= 3.597379684448242 for iteration= 69\n",
      "loss= 4.715239524841309 for iteration= 70\n",
      "loss= 2.92511248588562 for iteration= 71\n",
      "loss= 3.9859390258789062 for iteration= 72\n",
      "loss= 4.245475769042969 for iteration= 73\n",
      "loss= 4.604112148284912 for iteration= 74\n",
      "loss= 5.684231758117676 for iteration= 75\n",
      "loss= 3.989107370376587 for iteration= 76\n",
      "loss= 4.0853657722473145 for iteration= 77\n",
      "loss= 4.692570209503174 for iteration= 78\n",
      "loss= 3.245961904525757 for iteration= 79\n",
      "loss= 4.520678997039795 for iteration= 80\n",
      "loss= 3.113483428955078 for iteration= 81\n",
      "loss= 3.679408550262451 for iteration= 82\n",
      "loss= 4.159715175628662 for iteration= 83\n",
      "loss= 3.582089900970459 for iteration= 84\n",
      "loss= 4.135881423950195 for iteration= 85\n",
      "loss= 3.532268762588501 for iteration= 86\n",
      "loss= 3.96895170211792 for iteration= 87\n",
      "loss= 4.226851463317871 for iteration= 88\n",
      "loss= 3.731095314025879 for iteration= 89\n",
      "loss= 3.57962703704834 for iteration= 90\n",
      "loss= 3.9172310829162598 for iteration= 91\n",
      "loss= 5.100175857543945 for iteration= 92\n",
      "loss= 3.5807008743286133 for iteration= 93\n",
      "loss= 3.907198429107666 for iteration= 94\n",
      "loss= 3.2626028060913086 for iteration= 95\n",
      "loss= 4.671314239501953 for iteration= 96\n",
      "loss= 4.0393242835998535 for iteration= 97\n",
      "loss= 3.5147736072540283 for iteration= 98\n",
      "loss= 3.39492130279541 for iteration= 99\n",
      "loss= 2.7868399620056152 for iteration= 100\n",
      "loss= 3.316152334213257 for iteration= 101\n",
      "loss= 3.5570266246795654 for iteration= 102\n",
      "loss= 4.105041027069092 for iteration= 103\n",
      "loss= 3.7471067905426025 for iteration= 104\n",
      "loss= 4.204664707183838 for iteration= 105\n",
      "loss= 3.0888872146606445 for iteration= 106\n",
      "loss= 3.278733730316162 for iteration= 107\n",
      "loss= 3.514514207839966 for iteration= 108\n",
      "loss= 3.8083300590515137 for iteration= 109\n",
      "loss= 5.134323596954346 for iteration= 110\n",
      "loss= 3.0570881366729736 for iteration= 111\n",
      "loss= 3.814640522003174 for iteration= 112\n",
      "loss= 3.0203402042388916 for iteration= 113\n",
      "loss= 4.137658596038818 for iteration= 114\n",
      "loss= 3.208005905151367 for iteration= 115\n",
      "loss= 3.5031368732452393 for iteration= 116\n",
      "loss= 3.525283098220825 for iteration= 117\n",
      "loss= 3.147385597229004 for iteration= 118\n",
      "loss= 2.7903201580047607 for iteration= 119\n",
      "loss= 3.1947081089019775 for iteration= 120\n",
      "loss= 3.0805697441101074 for iteration= 121\n",
      "loss= 3.660216808319092 for iteration= 122\n",
      "loss= 3.268317699432373 for iteration= 123\n",
      "loss= 3.2396559715270996 for iteration= 124\n",
      "loss= 2.8013463020324707 for iteration= 125\n",
      "loss= 3.284306049346924 for iteration= 126\n",
      "loss= 3.924774169921875 for iteration= 127\n",
      "loss= 3.156689405441284 for iteration= 128\n",
      "loss= 3.021916389465332 for iteration= 129\n",
      "loss= 3.2869317531585693 for iteration= 130\n",
      "loss= 3.1575090885162354 for iteration= 131\n",
      "loss= 3.2093541622161865 for iteration= 132\n",
      "loss= 4.37120246887207 for iteration= 133\n",
      "loss= 3.2138450145721436 for iteration= 134\n",
      "loss= 3.2305307388305664 for iteration= 135\n",
      "loss= 3.018899440765381 for iteration= 136\n",
      "loss= 3.0386745929718018 for iteration= 137\n",
      "loss= 3.313290596008301 for iteration= 138\n",
      "loss= 3.2732110023498535 for iteration= 139\n",
      "loss= 3.5465903282165527 for iteration= 140\n",
      "loss= 3.4803125858306885 for iteration= 141\n",
      "loss= 3.0865018367767334 for iteration= 142\n",
      "loss= 3.137598752975464 for iteration= 143\n",
      "loss= 3.020200490951538 for iteration= 144\n",
      "loss= 3.948974609375 for iteration= 145\n",
      "loss= 4.074588775634766 for iteration= 146\n",
      "loss= 3.1760573387145996 for iteration= 147\n",
      "loss= 2.7194881439208984 for iteration= 148\n",
      "loss= 3.4197468757629395 for iteration= 149\n",
      "loss= 3.6211600303649902 for iteration= 150\n",
      "loss= 4.080560684204102 for iteration= 151\n",
      "loss= 3.5142760276794434 for iteration= 152\n",
      "loss= 3.7702126502990723 for iteration= 153\n",
      "loss= 3.3772690296173096 for iteration= 154\n",
      "loss= 3.5483992099761963 for iteration= 155\n",
      "loss= 2.8632192611694336 for iteration= 156\n",
      "loss= 3.0081076622009277 for iteration= 157\n",
      "loss= 3.7325055599212646 for iteration= 158\n",
      "loss= 3.199950933456421 for iteration= 159\n",
      "loss= 2.8425750732421875 for iteration= 160\n",
      "loss= 3.445939540863037 for iteration= 161\n",
      "loss= 2.7404403686523438 for iteration= 162\n",
      "loss= 2.9514853954315186 for iteration= 163\n",
      "loss= 2.9773788452148438 for iteration= 164\n",
      "loss= 2.680211305618286 for iteration= 165\n",
      "loss= 2.7568728923797607 for iteration= 166\n",
      "loss= 3.178053617477417 for iteration= 167\n",
      "loss= 3.2002363204956055 for iteration= 168\n",
      "loss= 3.651153564453125 for iteration= 169\n",
      "loss= 3.2267696857452393 for iteration= 170\n",
      "loss= 3.1405115127563477 for iteration= 171\n",
      "loss= 3.220014810562134 for iteration= 172\n",
      "loss= 3.7820322513580322 for iteration= 173\n",
      "loss= 3.3215413093566895 for iteration= 174\n",
      "loss= 2.782860517501831 for iteration= 175\n",
      "loss= 3.7299561500549316 for iteration= 176\n",
      "loss= 4.233264923095703 for iteration= 177\n",
      "loss= 3.406114101409912 for iteration= 178\n",
      "loss= 2.9417078495025635 for iteration= 179\n",
      "loss= 2.675462484359741 for iteration= 180\n",
      "loss= 3.5688815116882324 for iteration= 181\n",
      "loss= 3.0771846771240234 for iteration= 182\n",
      "loss= 2.9545140266418457 for iteration= 183\n",
      "loss= 3.4214415550231934 for iteration= 184\n",
      "loss= 3.4471354484558105 for iteration= 185\n",
      "loss= 3.1084179878234863 for iteration= 186\n",
      "loss= 3.0373170375823975 for iteration= 187\n",
      "loss= 2.9868850708007812 for iteration= 188\n",
      "loss= 3.010131597518921 for iteration= 189\n",
      "loss= 3.4123451709747314 for iteration= 190\n",
      "loss= 3.1506078243255615 for iteration= 191\n",
      "loss= 2.82308292388916 for iteration= 192\n",
      "loss= 3.780909776687622 for iteration= 193\n",
      "loss= 3.248237371444702 for iteration= 194\n",
      "loss= 2.9924702644348145 for iteration= 195\n",
      "loss= 3.158118963241577 for iteration= 196\n",
      "loss= 2.8574793338775635 for iteration= 197\n",
      "loss= 2.7937092781066895 for iteration= 198\n",
      "loss= 2.7433865070343018 for iteration= 199\n",
      "loss= 2.7427310943603516 for iteration= 200\n",
      "loss= 3.3529348373413086 for iteration= 201\n",
      "loss= 2.8157546520233154 for iteration= 202\n",
      "loss= 2.9069747924804688 for iteration= 203\n",
      "loss= 3.867550849914551 for iteration= 204\n",
      "loss= 3.018840789794922 for iteration= 205\n",
      "loss= 3.5996010303497314 for iteration= 206\n",
      "loss= 3.2701144218444824 for iteration= 207\n",
      "loss= 2.9930620193481445 for iteration= 208\n",
      "loss= 3.0501041412353516 for iteration= 209\n",
      "loss= 3.4377381801605225 for iteration= 210\n",
      "loss= 2.629753589630127 for iteration= 211\n",
      "loss= 4.291600704193115 for iteration= 212\n",
      "loss= 4.137400150299072 for iteration= 213\n",
      "loss= 3.270833969116211 for iteration= 214\n",
      "loss= 3.1013903617858887 for iteration= 215\n",
      "loss= 3.366004228591919 for iteration= 216\n",
      "loss= 3.5687928199768066 for iteration= 217\n",
      "loss= 3.2965848445892334 for iteration= 218\n",
      "loss= 3.081930160522461 for iteration= 219\n",
      "loss= 2.973459005355835 for iteration= 220\n",
      "loss= 3.050806999206543 for iteration= 221\n",
      "loss= 2.95003342628479 for iteration= 222\n",
      "loss= 3.1844406127929688 for iteration= 223\n",
      "loss= 2.84277081489563 for iteration= 224\n",
      "loss= 2.9500362873077393 for iteration= 225\n",
      "loss= 2.573002338409424 for iteration= 226\n",
      "loss= 3.1173288822174072 for iteration= 227\n",
      "loss= 2.892869710922241 for iteration= 228\n",
      "loss= 2.868516206741333 for iteration= 229\n",
      "loss= 2.4292168617248535 for iteration= 230\n",
      "loss= 2.8681228160858154 for iteration= 231\n",
      "loss= 2.8224637508392334 for iteration= 232\n",
      "loss= 3.2067322731018066 for iteration= 233\n",
      "loss= 3.0648412704467773 for iteration= 234\n",
      "loss= 2.7617249488830566 for iteration= 235\n",
      "loss= 3.087653398513794 for iteration= 236\n",
      "loss= 2.665576696395874 for iteration= 237\n",
      "loss= 3.2781476974487305 for iteration= 238\n",
      "loss= 3.864483118057251 for iteration= 239\n",
      "loss= 3.123643398284912 for iteration= 240\n",
      "loss= 3.2080397605895996 for iteration= 241\n",
      "loss= 2.9175431728363037 for iteration= 242\n",
      "loss= 3.149632453918457 for iteration= 243\n",
      "loss= 2.799447774887085 for iteration= 244\n",
      "loss= 2.982914447784424 for iteration= 245\n",
      "loss= 2.7485191822052 for iteration= 246\n",
      "loss= 3.574918270111084 for iteration= 247\n",
      "loss= 2.975823402404785 for iteration= 248\n",
      "loss= 2.9905638694763184 for iteration= 249\n",
      "loss= 2.99919056892395 for iteration= 250\n",
      "loss= 2.729630708694458 for iteration= 251\n",
      "loss= 2.91715931892395 for iteration= 252\n",
      "loss= 2.6973495483398438 for iteration= 253\n",
      "loss= 3.204465389251709 for iteration= 254\n",
      "loss= 2.6336872577667236 for iteration= 255\n",
      "loss= 3.3885374069213867 for iteration= 256\n",
      "loss= 2.770906686782837 for iteration= 257\n",
      "loss= 3.3274734020233154 for iteration= 258\n",
      "loss= 3.3124139308929443 for iteration= 259\n",
      "loss= 2.927445888519287 for iteration= 260\n",
      "loss= 3.1333906650543213 for iteration= 261\n",
      "loss= 2.530097246170044 for iteration= 262\n",
      "loss= 2.9436473846435547 for iteration= 263\n",
      "loss= 2.6157736778259277 for iteration= 264\n",
      "loss= 3.168022394180298 for iteration= 265\n",
      "loss= 2.761603355407715 for iteration= 266\n",
      "loss= 3.045442819595337 for iteration= 267\n",
      "loss= 2.8748693466186523 for iteration= 268\n",
      "loss= 2.4429240226745605 for iteration= 269\n",
      "loss= 2.8264763355255127 for iteration= 270\n",
      "loss= 2.4128355979919434 for iteration= 271\n",
      "loss= 3.1269326210021973 for iteration= 272\n",
      "loss= 3.1485865116119385 for iteration= 273\n",
      "loss= 2.8939716815948486 for iteration= 274\n",
      "loss= 3.323370933532715 for iteration= 275\n",
      "loss= 3.0207316875457764 for iteration= 276\n",
      "loss= 2.5551016330718994 for iteration= 277\n",
      "loss= 2.7982826232910156 for iteration= 278\n",
      "loss= 2.979353904724121 for iteration= 279\n",
      "loss= 2.8704137802124023 for iteration= 280\n",
      "loss= 3.149841070175171 for iteration= 281\n",
      "loss= 2.806555986404419 for iteration= 282\n",
      "loss= 2.364633083343506 for iteration= 283\n",
      "loss= 2.825474739074707 for iteration= 284\n",
      "loss= 2.8980050086975098 for iteration= 285\n",
      "loss= 3.08747935295105 for iteration= 286\n",
      "loss= 2.5528335571289062 for iteration= 287\n",
      "loss= 3.337994337081909 for iteration= 288\n",
      "loss= 3.214909791946411 for iteration= 289\n",
      "loss= 3.0177676677703857 for iteration= 290\n",
      "loss= 2.8885366916656494 for iteration= 291\n",
      "loss= 3.021167039871216 for iteration= 292\n",
      "loss= 3.0049989223480225 for iteration= 293\n",
      "loss= 2.958462953567505 for iteration= 294\n",
      "loss= 3.659184455871582 for iteration= 295\n",
      "loss= 3.309148073196411 for iteration= 296\n",
      "loss= 3.0540292263031006 for iteration= 297\n",
      "loss= 3.0321998596191406 for iteration= 298\n",
      "loss= 3.142045259475708 for iteration= 299\n",
      "loss= 2.713280439376831 for iteration= 300\n",
      "loss= 2.998990297317505 for iteration= 301\n",
      "loss= 2.8375942707061768 for iteration= 302\n",
      "loss= 2.9216272830963135 for iteration= 303\n",
      "loss= 3.2883176803588867 for iteration= 304\n",
      "loss= 3.207486152648926 for iteration= 305\n",
      "loss= 2.874490261077881 for iteration= 306\n",
      "loss= 2.9355664253234863 for iteration= 307\n",
      "loss= 2.718557119369507 for iteration= 308\n",
      "loss= 2.7220394611358643 for iteration= 309\n",
      "loss= 2.5978307723999023 for iteration= 310\n",
      "loss= 2.9564762115478516 for iteration= 311\n",
      "loss= 2.8935446739196777 for iteration= 312\n",
      "loss= 3.541696310043335 for iteration= 313\n",
      "loss= 3.3988900184631348 for iteration= 314\n",
      "loss= 2.4292871952056885 for iteration= 315\n",
      "loss= 2.7496702671051025 for iteration= 316\n",
      "loss= 3.257660388946533 for iteration= 317\n",
      "loss= 3.120872735977173 for iteration= 318\n",
      "loss= 3.1459808349609375 for iteration= 319\n",
      "loss= 2.774289131164551 for iteration= 320\n",
      "loss= 2.7068629264831543 for iteration= 321\n",
      "loss= 2.855992317199707 for iteration= 322\n",
      "loss= 2.6822118759155273 for iteration= 323\n",
      "loss= 3.1014339923858643 for iteration= 324\n",
      "loss= 3.597350835800171 for iteration= 325\n",
      "loss= 2.725365400314331 for iteration= 326\n",
      "loss= 3.105102777481079 for iteration= 327\n",
      "loss= 2.418097496032715 for iteration= 328\n",
      "loss= 2.7746050357818604 for iteration= 329\n",
      "loss= 3.136089324951172 for iteration= 330\n",
      "loss= 2.846646547317505 for iteration= 331\n",
      "loss= 2.7514450550079346 for iteration= 332\n",
      "loss= 2.945917844772339 for iteration= 333\n",
      "loss= 3.775617837905884 for iteration= 334\n",
      "loss= 2.968001127243042 for iteration= 335\n",
      "loss= 3.213228702545166 for iteration= 336\n",
      "loss= 2.9471230506896973 for iteration= 337\n",
      "loss= 3.0878703594207764 for iteration= 338\n",
      "loss= 3.033236503601074 for iteration= 339\n",
      "loss= 3.07700777053833 for iteration= 340\n",
      "loss= 2.691437005996704 for iteration= 341\n",
      "loss= 2.9165022373199463 for iteration= 342\n",
      "loss= 2.9041202068328857 for iteration= 343\n",
      "loss= 2.9291319847106934 for iteration= 344\n",
      "loss= 3.2323923110961914 for iteration= 345\n",
      "loss= 2.7012953758239746 for iteration= 346\n",
      "loss= 2.762173652648926 for iteration= 347\n",
      "loss= 3.1329689025878906 for iteration= 348\n",
      "loss= 2.9114184379577637 for iteration= 349\n",
      "loss= 2.8322553634643555 for iteration= 350\n",
      "loss= 2.5504846572875977 for iteration= 351\n",
      "loss= 2.8405094146728516 for iteration= 352\n",
      "loss= 2.8870410919189453 for iteration= 353\n",
      "loss= 2.689511775970459 for iteration= 354\n",
      "loss= 2.368894577026367 for iteration= 355\n",
      "loss= 2.4319190979003906 for iteration= 356\n",
      "loss= 2.6273348331451416 for iteration= 357\n",
      "loss= 2.5576610565185547 for iteration= 358\n",
      "loss= 2.8620047569274902 for iteration= 359\n",
      "loss= 3.0882408618927 for iteration= 360\n",
      "loss= 2.9582130908966064 for iteration= 361\n",
      "loss= 3.0061981678009033 for iteration= 362\n",
      "loss= 2.74651837348938 for iteration= 363\n",
      "loss= 2.5978667736053467 for iteration= 364\n",
      "loss= 2.6495330333709717 for iteration= 365\n",
      "loss= 2.659587860107422 for iteration= 366\n",
      "loss= 3.0261497497558594 for iteration= 367\n",
      "loss= 3.0000510215759277 for iteration= 368\n",
      "loss= 3.451256513595581 for iteration= 369\n",
      "loss= 3.0010364055633545 for iteration= 370\n",
      "loss= 3.0034396648406982 for iteration= 371\n",
      "loss= 2.4418935775756836 for iteration= 372\n",
      "loss= 2.646409749984741 for iteration= 373\n",
      "loss= 2.6511123180389404 for iteration= 374\n",
      "loss= 2.6398091316223145 for iteration= 375\n",
      "loss= 2.659641981124878 for iteration= 376\n",
      "loss= 2.485046625137329 for iteration= 377\n",
      "loss= 2.4466729164123535 for iteration= 378\n",
      "loss= 3.5963311195373535 for iteration= 379\n",
      "loss= 2.786202907562256 for iteration= 380\n",
      "loss= 3.139507293701172 for iteration= 381\n",
      "loss= 2.648559331893921 for iteration= 382\n",
      "loss= 2.7536468505859375 for iteration= 383\n",
      "loss= 2.7353780269622803 for iteration= 384\n",
      "loss= 2.7905194759368896 for iteration= 385\n",
      "loss= 3.3018603324890137 for iteration= 386\n",
      "loss= 2.7330493927001953 for iteration= 387\n",
      "loss= 2.5167109966278076 for iteration= 388\n",
      "loss= 2.695441722869873 for iteration= 389\n",
      "loss= 2.931684970855713 for iteration= 390\n",
      "loss= 3.1606972217559814 for iteration= 391\n",
      "loss= 2.68176007270813 for iteration= 392\n",
      "loss= 2.7637884616851807 for iteration= 393\n",
      "loss= 2.878228187561035 for iteration= 394\n",
      "loss= 2.684377908706665 for iteration= 395\n",
      "loss= 2.811009168624878 for iteration= 396\n",
      "loss= 2.8668529987335205 for iteration= 397\n",
      "loss= 3.0050337314605713 for iteration= 398\n",
      "loss= 3.010347604751587 for iteration= 399\n",
      "loss= 2.829944610595703 for iteration= 400\n",
      "loss= 2.5143024921417236 for iteration= 401\n",
      "loss= 3.544203758239746 for iteration= 402\n",
      "loss= 3.1960766315460205 for iteration= 403\n",
      "loss= 2.9224860668182373 for iteration= 404\n",
      "loss= 2.6075339317321777 for iteration= 405\n",
      "loss= 3.2246310710906982 for iteration= 406\n",
      "loss= 2.730294704437256 for iteration= 407\n",
      "loss= 2.9452176094055176 for iteration= 408\n",
      "loss= 2.973884344100952 for iteration= 409\n",
      "loss= 3.193359136581421 for iteration= 410\n",
      "loss= 2.919466972351074 for iteration= 411\n",
      "loss= 2.630289316177368 for iteration= 412\n",
      "loss= 2.6950385570526123 for iteration= 413\n",
      "loss= 2.7327170372009277 for iteration= 414\n",
      "loss= 3.0481858253479004 for iteration= 415\n",
      "loss= 2.6574838161468506 for iteration= 416\n",
      "loss= 2.820909261703491 for iteration= 417\n",
      "loss= 2.5378658771514893 for iteration= 418\n",
      "loss= 2.8104777336120605 for iteration= 419\n",
      "loss= 2.6032445430755615 for iteration= 420\n",
      "loss= 2.700788974761963 for iteration= 421\n",
      "loss= 2.651906967163086 for iteration= 422\n",
      "loss= 2.9371674060821533 for iteration= 423\n",
      "loss= 2.5665009021759033 for iteration= 424\n",
      "loss= 2.9419476985931396 for iteration= 425\n",
      "loss= 3.1522302627563477 for iteration= 426\n",
      "loss= 2.4396142959594727 for iteration= 427\n",
      "loss= 2.2819814682006836 for iteration= 428\n",
      "loss= 2.5916388034820557 for iteration= 429\n",
      "loss= 2.535421371459961 for iteration= 430\n",
      "loss= 2.9004297256469727 for iteration= 431\n",
      "loss= 3.06430983543396 for iteration= 432\n",
      "loss= 2.9593687057495117 for iteration= 433\n",
      "loss= 3.049168825149536 for iteration= 434\n",
      "loss= 2.7549831867218018 for iteration= 435\n",
      "loss= 2.7344272136688232 for iteration= 436\n",
      "loss= 3.1113312244415283 for iteration= 437\n",
      "loss= 2.8621323108673096 for iteration= 438\n",
      "loss= 2.65455961227417 for iteration= 439\n",
      "loss= 3.2144103050231934 for iteration= 440\n",
      "loss= 2.6356022357940674 for iteration= 441\n",
      "loss= 2.6624388694763184 for iteration= 442\n",
      "loss= 2.682018280029297 for iteration= 443\n",
      "loss= 3.406135320663452 for iteration= 444\n",
      "loss= 3.058481454849243 for iteration= 445\n",
      "loss= 2.8091559410095215 for iteration= 446\n",
      "loss= 2.8079185485839844 for iteration= 447\n",
      "loss= 2.611726760864258 for iteration= 448\n",
      "loss= 2.4836580753326416 for iteration= 449\n",
      "loss= 2.370386838912964 for iteration= 450\n",
      "loss= 2.6657590866088867 for iteration= 451\n",
      "loss= 2.8661279678344727 for iteration= 452\n",
      "loss= 3.343722343444824 for iteration= 453\n",
      "loss= 2.7543201446533203 for iteration= 454\n",
      "loss= 2.8794965744018555 for iteration= 455\n",
      "loss= 2.849125623703003 for iteration= 456\n",
      "loss= 2.7302744388580322 for iteration= 457\n",
      "loss= 2.7132065296173096 for iteration= 458\n",
      "loss= 2.521486520767212 for iteration= 459\n",
      "loss= 2.8484039306640625 for iteration= 460\n",
      "loss= 2.9229371547698975 for iteration= 461\n",
      "loss= 2.930175542831421 for iteration= 462\n",
      "loss= 3.0688018798828125 for iteration= 463\n",
      "loss= 2.3847999572753906 for iteration= 464\n",
      "loss= 2.871868371963501 for iteration= 465\n",
      "loss= 3.0323383808135986 for iteration= 466\n",
      "loss= 2.963886022567749 for iteration= 467\n",
      "loss= 2.759681224822998 for iteration= 468\n",
      "loss= 3.048309564590454 for iteration= 469\n",
      "loss= 2.9479095935821533 for iteration= 470\n",
      "loss= 3.056490898132324 for iteration= 471\n",
      "loss= 2.6243059635162354 for iteration= 472\n",
      "loss= 2.9009861946105957 for iteration= 473\n",
      "loss= 2.342737913131714 for iteration= 474\n",
      "loss= 2.818215847015381 for iteration= 475\n",
      "loss= 3.038999080657959 for iteration= 476\n",
      "loss= 2.9823834896087646 for iteration= 477\n",
      "loss= 2.910694122314453 for iteration= 478\n",
      "loss= 2.650829315185547 for iteration= 479\n",
      "loss= 3.0918235778808594 for iteration= 480\n",
      "loss= 2.753812789916992 for iteration= 481\n",
      "loss= 2.8578832149505615 for iteration= 482\n",
      "loss= 2.95780086517334 for iteration= 483\n",
      "loss= 2.466991662979126 for iteration= 484\n",
      "loss= 2.423139810562134 for iteration= 485\n",
      "loss= 2.928446054458618 for iteration= 486\n",
      "loss= 2.5668697357177734 for iteration= 487\n",
      "loss= 2.944201707839966 for iteration= 488\n",
      "loss= 2.462559223175049 for iteration= 489\n",
      "loss= 3.1995949745178223 for iteration= 490\n",
      "loss= 2.837540626525879 for iteration= 491\n",
      "loss= 2.9130024909973145 for iteration= 492\n",
      "loss= 3.1161487102508545 for iteration= 493\n",
      "loss= 2.453320264816284 for iteration= 494\n",
      "loss= 2.6191515922546387 for iteration= 495\n",
      "loss= 2.8682985305786133 for iteration= 496\n",
      "loss= 3.0384585857391357 for iteration= 497\n",
      "loss= 2.891362428665161 for iteration= 498\n",
      "loss= 3.0661404132843018 for iteration= 499\n",
      "loss= 3.1457767486572266 for iteration= 500\n",
      "loss= 2.9849579334259033 for iteration= 501\n",
      "loss= 2.8693907260894775 for iteration= 502\n",
      "loss= 2.947232484817505 for iteration= 503\n",
      "loss= 3.1752219200134277 for iteration= 504\n",
      "loss= 2.8782458305358887 for iteration= 505\n",
      "loss= 2.5440022945404053 for iteration= 506\n",
      "loss= 2.8154964447021484 for iteration= 507\n",
      "loss= 2.863645553588867 for iteration= 508\n",
      "loss= 2.4626314640045166 for iteration= 509\n",
      "loss= 2.7137978076934814 for iteration= 510\n",
      "loss= 2.8189616203308105 for iteration= 511\n",
      "loss= 2.6420583724975586 for iteration= 512\n",
      "loss= 2.9359230995178223 for iteration= 513\n",
      "loss= 2.5767812728881836 for iteration= 514\n",
      "loss= 2.6749160289764404 for iteration= 515\n",
      "loss= 2.6997218132019043 for iteration= 516\n",
      "loss= 2.899509906768799 for iteration= 517\n",
      "loss= 2.477562427520752 for iteration= 518\n",
      "loss= 3.1381053924560547 for iteration= 519\n",
      "loss= 2.474194049835205 for iteration= 520\n",
      "loss= 2.9944710731506348 for iteration= 521\n",
      "loss= 2.925804615020752 for iteration= 522\n",
      "loss= 2.412651300430298 for iteration= 523\n",
      "loss= 2.9966137409210205 for iteration= 524\n",
      "loss= 2.579228401184082 for iteration= 525\n",
      "loss= 2.9636547565460205 for iteration= 526\n",
      "loss= 2.579164505004883 for iteration= 527\n",
      "loss= 2.7513749599456787 for iteration= 528\n",
      "loss= 2.8923728466033936 for iteration= 529\n",
      "loss= 2.9378397464752197 for iteration= 530\n",
      "loss= 2.5759122371673584 for iteration= 531\n",
      "loss= 2.8651702404022217 for iteration= 532\n",
      "loss= 2.746173620223999 for iteration= 533\n",
      "loss= 3.1415069103240967 for iteration= 534\n",
      "loss= 2.615072727203369 for iteration= 535\n",
      "loss= 2.9326171875 for iteration= 536\n",
      "loss= 2.7326278686523438 for iteration= 537\n",
      "loss= 2.9158713817596436 for iteration= 538\n",
      "loss= 2.78755259513855 for iteration= 539\n",
      "loss= 2.862097978591919 for iteration= 540\n",
      "loss= 2.591388463973999 for iteration= 541\n",
      "loss= 2.654954433441162 for iteration= 542\n",
      "loss= 2.5492405891418457 for iteration= 543\n",
      "loss= 3.3911592960357666 for iteration= 544\n",
      "loss= 2.848278045654297 for iteration= 545\n",
      "loss= 3.02835750579834 for iteration= 546\n",
      "loss= 2.552854299545288 for iteration= 547\n",
      "loss= 2.776928424835205 for iteration= 548\n",
      "loss= 3.0264980792999268 for iteration= 549\n",
      "loss= 3.483482599258423 for iteration= 550\n",
      "loss= 2.992952585220337 for iteration= 551\n",
      "loss= 2.737971067428589 for iteration= 552\n",
      "loss= 2.928121566772461 for iteration= 553\n",
      "loss= 2.874307155609131 for iteration= 554\n",
      "loss= 2.626866579055786 for iteration= 555\n",
      "loss= 2.359842300415039 for iteration= 556\n",
      "loss= 2.7567906379699707 for iteration= 557\n",
      "loss= 2.6388449668884277 for iteration= 558\n",
      "loss= 3.2487571239471436 for iteration= 559\n",
      "loss= 2.5744988918304443 for iteration= 560\n",
      "loss= 2.795804023742676 for iteration= 561\n",
      "loss= 2.6397194862365723 for iteration= 562\n",
      "loss= 3.230555295944214 for iteration= 563\n",
      "loss= 2.9061880111694336 for iteration= 564\n",
      "loss= 2.9263837337493896 for iteration= 565\n",
      "loss= 2.802015542984009 for iteration= 566\n",
      "loss= 2.8002090454101562 for iteration= 567\n",
      "loss= 2.9315738677978516 for iteration= 568\n",
      "loss= 3.2129876613616943 for iteration= 569\n",
      "loss= 2.9626951217651367 for iteration= 570\n",
      "loss= 2.510667562484741 for iteration= 571\n",
      "loss= 2.984039306640625 for iteration= 572\n",
      "loss= 2.892552375793457 for iteration= 573\n",
      "loss= 2.6784937381744385 for iteration= 574\n",
      "loss= 2.8761000633239746 for iteration= 575\n",
      "loss= 2.872410535812378 for iteration= 576\n",
      "loss= 2.507723331451416 for iteration= 577\n",
      "loss= 3.3032870292663574 for iteration= 578\n",
      "loss= 2.9555368423461914 for iteration= 579\n",
      "loss= 2.823005199432373 for iteration= 580\n",
      "loss= 2.7700483798980713 for iteration= 581\n",
      "loss= 2.996890068054199 for iteration= 582\n",
      "loss= 2.825591802597046 for iteration= 583\n",
      "loss= 3.262690305709839 for iteration= 584\n",
      "loss= 2.938525915145874 for iteration= 585\n",
      "loss= 2.884752035140991 for iteration= 586\n",
      "loss= 2.6852636337280273 for iteration= 587\n",
      "loss= 2.9249320030212402 for iteration= 588\n",
      "loss= 2.8416566848754883 for iteration= 589\n",
      "loss= 2.5507004261016846 for iteration= 590\n",
      "loss= 2.6054227352142334 for iteration= 591\n",
      "loss= 2.9184679985046387 for iteration= 592\n",
      "loss= 2.9152204990386963 for iteration= 593\n",
      "loss= 2.7473320960998535 for iteration= 594\n",
      "loss= 2.844818592071533 for iteration= 595\n",
      "loss= 2.4720544815063477 for iteration= 596\n",
      "loss= 2.709447145462036 for iteration= 597\n",
      "loss= 2.8660643100738525 for iteration= 598\n",
      "loss= 2.943746566772461 for iteration= 599\n",
      "loss= 2.6530649662017822 for iteration= 600\n",
      "loss= 2.826594829559326 for iteration= 601\n",
      "loss= 2.6662251949310303 for iteration= 602\n",
      "loss= 3.057603120803833 for iteration= 603\n",
      "loss= 2.981203079223633 for iteration= 604\n",
      "loss= 2.928288221359253 for iteration= 605\n",
      "loss= 2.4369490146636963 for iteration= 606\n",
      "loss= 3.1452078819274902 for iteration= 607\n",
      "loss= 3.214836597442627 for iteration= 608\n",
      "loss= 2.8915953636169434 for iteration= 609\n",
      "loss= 2.573021173477173 for iteration= 610\n",
      "loss= 2.472839593887329 for iteration= 611\n",
      "loss= 3.2407617568969727 for iteration= 612\n",
      "loss= 2.710965871810913 for iteration= 613\n",
      "loss= 3.268991470336914 for iteration= 614\n",
      "loss= 2.6040759086608887 for iteration= 615\n",
      "loss= 3.1397767066955566 for iteration= 616\n",
      "loss= 3.2087674140930176 for iteration= 617\n",
      "loss= 2.5823819637298584 for iteration= 618\n",
      "loss= 2.545031785964966 for iteration= 619\n",
      "loss= 2.9395008087158203 for iteration= 620\n",
      "loss= 2.770606279373169 for iteration= 621\n",
      "loss= 2.7601053714752197 for iteration= 622\n",
      "loss= 2.773923397064209 for iteration= 623\n",
      "loss= 2.896812915802002 for iteration= 624\n",
      "loss= 2.2106237411499023 for iteration= 625\n",
      "loss= 2.42854380607605 for iteration= 626\n",
      "loss= 2.7889087200164795 for iteration= 627\n",
      "loss= 3.3922348022460938 for iteration= 628\n",
      "loss= 2.998401403427124 for iteration= 629\n",
      "loss= 3.0141983032226562 for iteration= 630\n",
      "loss= 3.079439878463745 for iteration= 631\n",
      "loss= 2.8776557445526123 for iteration= 632\n",
      "loss= 2.9727747440338135 for iteration= 633\n",
      "loss= 2.680452346801758 for iteration= 634\n",
      "loss= 2.8703625202178955 for iteration= 635\n",
      "loss= 2.8879477977752686 for iteration= 636\n",
      "loss= 2.42048716545105 for iteration= 637\n",
      "loss= 2.751652479171753 for iteration= 638\n",
      "loss= 2.6107137203216553 for iteration= 639\n",
      "loss= 2.7647526264190674 for iteration= 640\n",
      "loss= 2.902350664138794 for iteration= 641\n",
      "loss= 2.6102468967437744 for iteration= 642\n",
      "loss= 3.0267903804779053 for iteration= 643\n",
      "loss= 3.009368419647217 for iteration= 644\n",
      "loss= 2.791870594024658 for iteration= 645\n",
      "loss= 2.7913901805877686 for iteration= 646\n",
      "loss= 2.7833855152130127 for iteration= 647\n",
      "loss= 3.204890489578247 for iteration= 648\n",
      "loss= 2.7911972999572754 for iteration= 649\n",
      "loss= 3.0487220287323 for iteration= 650\n",
      "loss= 2.868896245956421 for iteration= 651\n",
      "loss= 2.2651312351226807 for iteration= 652\n",
      "loss= 3.245264768600464 for iteration= 653\n",
      "loss= 2.665508508682251 for iteration= 654\n",
      "loss= 2.659336805343628 for iteration= 655\n",
      "loss= 2.9247450828552246 for iteration= 656\n",
      "loss= 2.7170205116271973 for iteration= 657\n",
      "loss= 2.5348753929138184 for iteration= 658\n",
      "loss= 3.040170907974243 for iteration= 659\n",
      "loss= 2.935849666595459 for iteration= 660\n",
      "loss= 2.5799508094787598 for iteration= 661\n",
      "loss= 3.0117347240448 for iteration= 662\n",
      "loss= 2.739044427871704 for iteration= 663\n",
      "loss= 2.364529609680176 for iteration= 664\n",
      "loss= 3.186851978302002 for iteration= 665\n",
      "loss= 2.6899478435516357 for iteration= 666\n",
      "loss= 2.999457597732544 for iteration= 667\n",
      "loss= 2.5214030742645264 for iteration= 668\n",
      "loss= 2.549456834793091 for iteration= 669\n",
      "loss= 2.871365785598755 for iteration= 670\n",
      "loss= 2.709064483642578 for iteration= 671\n",
      "loss= 2.666656017303467 for iteration= 672\n",
      "loss= 2.604074239730835 for iteration= 673\n",
      "loss= 2.940674066543579 for iteration= 674\n",
      "loss= 2.8097097873687744 for iteration= 675\n",
      "loss= 2.7761597633361816 for iteration= 676\n",
      "loss= 3.0747292041778564 for iteration= 677\n",
      "loss= 2.801947832107544 for iteration= 678\n",
      "loss= 3.1353228092193604 for iteration= 679\n",
      "loss= 2.9890787601470947 for iteration= 680\n",
      "loss= 2.391899824142456 for iteration= 681\n",
      "loss= 2.852945566177368 for iteration= 682\n",
      "loss= 2.8183515071868896 for iteration= 683\n",
      "loss= 2.649967908859253 for iteration= 684\n",
      "loss= 2.8976104259490967 for iteration= 685\n",
      "loss= 2.8757481575012207 for iteration= 686\n",
      "loss= 2.882371664047241 for iteration= 687\n",
      "loss= 2.6369881629943848 for iteration= 688\n",
      "loss= 3.329369068145752 for iteration= 689\n",
      "loss= 2.6461215019226074 for iteration= 690\n",
      "loss= 2.634150266647339 for iteration= 691\n",
      "loss= 3.0361599922180176 for iteration= 692\n",
      "loss= 2.710149049758911 for iteration= 693\n",
      "loss= 2.827908992767334 for iteration= 694\n",
      "loss= 2.33522367477417 for iteration= 695\n",
      "loss= 2.5715577602386475 for iteration= 696\n",
      "loss= 2.992175340652466 for iteration= 697\n",
      "loss= 2.565579652786255 for iteration= 698\n",
      "loss= 3.0760674476623535 for iteration= 699\n",
      "loss= 2.7016732692718506 for iteration= 700\n",
      "loss= 2.61641788482666 for iteration= 701\n",
      "loss= 2.5170509815216064 for iteration= 702\n",
      "loss= 2.586110830307007 for iteration= 703\n",
      "loss= 2.855771064758301 for iteration= 704\n",
      "loss= 2.8288068771362305 for iteration= 705\n",
      "loss= 2.4883241653442383 for iteration= 706\n",
      "loss= 2.8410027027130127 for iteration= 707\n",
      "loss= 2.7312867641448975 for iteration= 708\n",
      "loss= 3.0218327045440674 for iteration= 709\n",
      "loss= 2.3927175998687744 for iteration= 710\n",
      "loss= 2.8864192962646484 for iteration= 711\n",
      "loss= 3.004849672317505 for iteration= 712\n",
      "loss= 3.011171340942383 for iteration= 713\n",
      "loss= 2.811394453048706 for iteration= 714\n",
      "loss= 2.20269513130188 for iteration= 715\n",
      "loss= 2.6372451782226562 for iteration= 716\n",
      "loss= 3.2730469703674316 for iteration= 717\n",
      "loss= 2.601870536804199 for iteration= 718\n",
      "loss= 2.4708502292633057 for iteration= 719\n",
      "loss= 2.6671180725097656 for iteration= 720\n",
      "loss= 2.6116347312927246 for iteration= 721\n",
      "loss= 2.7189412117004395 for iteration= 722\n",
      "loss= 2.826338291168213 for iteration= 723\n",
      "loss= 2.8216447830200195 for iteration= 724\n",
      "loss= 2.8605597019195557 for iteration= 725\n",
      "loss= 2.6006295680999756 for iteration= 726\n",
      "loss= 2.990215539932251 for iteration= 727\n",
      "loss= 2.836359977722168 for iteration= 728\n",
      "loss= 3.0068840980529785 for iteration= 729\n",
      "loss= 2.519106864929199 for iteration= 730\n",
      "loss= 2.433758497238159 for iteration= 731\n",
      "loss= 2.4673972129821777 for iteration= 732\n",
      "loss= 3.3416965007781982 for iteration= 733\n",
      "loss= 2.592012643814087 for iteration= 734\n",
      "loss= 2.8450753688812256 for iteration= 735\n",
      "loss= 2.114278554916382 for iteration= 736\n",
      "loss= 3.2885184288024902 for iteration= 737\n",
      "loss= 2.257340431213379 for iteration= 738\n",
      "loss= 3.155036687850952 for iteration= 739\n",
      "loss= 2.9023401737213135 for iteration= 740\n",
      "loss= 2.7791450023651123 for iteration= 741\n",
      "loss= 2.4552252292633057 for iteration= 742\n",
      "loss= 2.840264081954956 for iteration= 743\n",
      "loss= 2.7554006576538086 for iteration= 744\n",
      "loss= 3.026146650314331 for iteration= 745\n",
      "loss= 3.032714366912842 for iteration= 746\n",
      "loss= 2.50041127204895 for iteration= 747\n",
      "loss= 3.0925729274749756 for iteration= 748\n",
      "loss= 2.457418441772461 for iteration= 749\n",
      "loss= 2.368722915649414 for iteration= 750\n",
      "loss= 2.7758913040161133 for iteration= 751\n",
      "loss= 2.4235622882843018 for iteration= 752\n",
      "loss= 2.6697030067443848 for iteration= 753\n",
      "loss= 2.8370461463928223 for iteration= 754\n",
      "loss= 2.4957852363586426 for iteration= 755\n",
      "loss= 2.631840705871582 for iteration= 756\n",
      "loss= 2.9833879470825195 for iteration= 757\n",
      "loss= 2.656482696533203 for iteration= 758\n",
      "loss= 3.179955244064331 for iteration= 759\n",
      "loss= 2.577678680419922 for iteration= 760\n",
      "loss= 2.8105480670928955 for iteration= 761\n",
      "loss= 2.5654234886169434 for iteration= 762\n",
      "loss= 2.800121784210205 for iteration= 763\n",
      "loss= 2.8824429512023926 for iteration= 764\n",
      "loss= 2.9958231449127197 for iteration= 765\n",
      "loss= 2.5213489532470703 for iteration= 766\n",
      "loss= 2.533263921737671 for iteration= 767\n",
      "loss= 2.536867141723633 for iteration= 768\n",
      "loss= 2.852452278137207 for iteration= 769\n",
      "loss= 2.6819493770599365 for iteration= 770\n",
      "loss= 2.411964178085327 for iteration= 771\n",
      "loss= 2.4225454330444336 for iteration= 772\n",
      "loss= 3.1757378578186035 for iteration= 773\n",
      "loss= 3.0076980590820312 for iteration= 774\n",
      "loss= 2.485353469848633 for iteration= 775\n",
      "loss= 3.2386062145233154 for iteration= 776\n",
      "loss= 3.0788564682006836 for iteration= 777\n",
      "loss= 2.561768054962158 for iteration= 778\n",
      "loss= 2.913539171218872 for iteration= 779\n",
      "loss= 2.9589033126831055 for iteration= 780\n",
      "loss= 2.549105167388916 for iteration= 781\n",
      "loss= 2.528278350830078 for iteration= 782\n",
      "loss= 2.9590859413146973 for iteration= 783\n",
      "loss= 3.1160471439361572 for iteration= 784\n",
      "loss= 3.1048431396484375 for iteration= 785\n",
      "loss= 2.496701955795288 for iteration= 786\n",
      "loss= 2.7428128719329834 for iteration= 787\n",
      "loss= 2.825650691986084 for iteration= 788\n",
      "loss= 3.5257155895233154 for iteration= 789\n",
      "loss= 2.7926971912384033 for iteration= 790\n",
      "loss= 2.6192073822021484 for iteration= 791\n",
      "loss= 2.825329065322876 for iteration= 792\n",
      "loss= 3.128750801086426 for iteration= 793\n",
      "loss= 2.8213915824890137 for iteration= 794\n",
      "loss= 2.5928258895874023 for iteration= 795\n",
      "loss= 2.6063969135284424 for iteration= 796\n",
      "loss= 3.009324550628662 for iteration= 797\n",
      "loss= 2.508697032928467 for iteration= 798\n",
      "loss= 2.536384105682373 for iteration= 799\n",
      "loss= 2.6614129543304443 for iteration= 800\n",
      "loss= 2.6417882442474365 for iteration= 801\n",
      "loss= 3.016376256942749 for iteration= 802\n",
      "loss= 2.942847728729248 for iteration= 803\n",
      "loss= 2.768972396850586 for iteration= 804\n",
      "loss= 2.4837207794189453 for iteration= 805\n",
      "loss= 2.5518503189086914 for iteration= 806\n",
      "loss= 2.6864607334136963 for iteration= 807\n",
      "loss= 2.0841808319091797 for iteration= 808\n",
      "loss= 2.9025022983551025 for iteration= 809\n",
      "loss= 2.716444492340088 for iteration= 810\n",
      "loss= 2.690070152282715 for iteration= 811\n",
      "loss= 2.596662998199463 for iteration= 812\n",
      "loss= 2.6305441856384277 for iteration= 813\n",
      "loss= 3.0309953689575195 for iteration= 814\n",
      "loss= 2.441964864730835 for iteration= 815\n",
      "loss= 2.824326276779175 for iteration= 816\n",
      "loss= 2.9321343898773193 for iteration= 817\n",
      "loss= 2.668179512023926 for iteration= 818\n",
      "loss= 2.867780923843384 for iteration= 819\n",
      "loss= 2.9534380435943604 for iteration= 820\n",
      "loss= 3.124481678009033 for iteration= 821\n",
      "loss= 2.4297220706939697 for iteration= 822\n",
      "loss= 2.5876305103302 for iteration= 823\n",
      "loss= 2.9906702041625977 for iteration= 824\n",
      "loss= 2.9256458282470703 for iteration= 825\n",
      "loss= 2.7858736515045166 for iteration= 826\n",
      "loss= 2.5448851585388184 for iteration= 827\n",
      "loss= 2.67781662940979 for iteration= 828\n",
      "loss= 3.0083696842193604 for iteration= 829\n",
      "loss= 2.5937914848327637 for iteration= 830\n",
      "loss= 2.830111503601074 for iteration= 831\n",
      "loss= 2.6102335453033447 for iteration= 832\n",
      "loss= 2.6338422298431396 for iteration= 833\n",
      "loss= 3.045064926147461 for iteration= 834\n",
      "loss= 2.754821300506592 for iteration= 835\n",
      "loss= 2.7001383304595947 for iteration= 836\n",
      "loss= 2.674097776412964 for iteration= 837\n",
      "loss= 2.6972146034240723 for iteration= 838\n",
      "loss= 2.8954405784606934 for iteration= 839\n",
      "loss= 2.4424045085906982 for iteration= 840\n",
      "loss= 2.570284843444824 for iteration= 841\n",
      "loss= 2.8667638301849365 for iteration= 842\n",
      "loss= 2.942473888397217 for iteration= 843\n",
      "loss= 2.713108539581299 for iteration= 844\n",
      "loss= 2.929603338241577 for iteration= 845\n",
      "loss= 2.8257250785827637 for iteration= 846\n",
      "loss= 2.2656304836273193 for iteration= 847\n",
      "loss= 2.8051884174346924 for iteration= 848\n",
      "loss= 2.693148374557495 for iteration= 849\n",
      "loss= 2.5093305110931396 for iteration= 850\n",
      "loss= 2.639273166656494 for iteration= 851\n",
      "loss= 2.3705530166625977 for iteration= 852\n",
      "loss= 2.7997934818267822 for iteration= 853\n",
      "loss= 3.0505592823028564 for iteration= 854\n",
      "loss= 2.610103130340576 for iteration= 855\n",
      "loss= 2.8149282932281494 for iteration= 856\n",
      "loss= 2.767704963684082 for iteration= 857\n",
      "loss= 2.582982301712036 for iteration= 858\n",
      "loss= 2.656691789627075 for iteration= 859\n",
      "loss= 2.2948265075683594 for iteration= 860\n",
      "loss= 2.911696672439575 for iteration= 861\n",
      "loss= 3.00839900970459 for iteration= 862\n",
      "loss= 2.794222593307495 for iteration= 863\n",
      "loss= 2.4536969661712646 for iteration= 864\n",
      "loss= 2.837850570678711 for iteration= 865\n",
      "loss= 3.235476016998291 for iteration= 866\n",
      "loss= 2.58325457572937 for iteration= 867\n",
      "loss= 2.7633578777313232 for iteration= 868\n",
      "loss= 2.726219892501831 for iteration= 869\n",
      "loss= 2.493802309036255 for iteration= 870\n",
      "loss= 2.514796018600464 for iteration= 871\n",
      "loss= 2.418976068496704 for iteration= 872\n",
      "loss= 2.3352558612823486 for iteration= 873\n",
      "loss= 2.822561264038086 for iteration= 874\n",
      "loss= 2.603039026260376 for iteration= 875\n",
      "loss= 3.165363311767578 for iteration= 876\n",
      "loss= 3.000263214111328 for iteration= 877\n",
      "loss= 3.0060620307922363 for iteration= 878\n",
      "loss= 2.5684103965759277 for iteration= 879\n",
      "loss= 2.974916934967041 for iteration= 880\n",
      "loss= 2.4541358947753906 for iteration= 881\n",
      "loss= 2.594632387161255 for iteration= 882\n",
      "loss= 3.0413687229156494 for iteration= 883\n",
      "loss= 2.920470714569092 for iteration= 884\n",
      "loss= 2.5107028484344482 for iteration= 885\n",
      "loss= 2.5862443447113037 for iteration= 886\n",
      "loss= 2.6982598304748535 for iteration= 887\n",
      "loss= 2.7748851776123047 for iteration= 888\n",
      "loss= 2.744563341140747 for iteration= 889\n",
      "loss= 2.773540735244751 for iteration= 890\n",
      "loss= 2.693650960922241 for iteration= 891\n",
      "loss= 3.4610493183135986 for iteration= 892\n",
      "loss= 3.394728660583496 for iteration= 893\n",
      "loss= 2.882903814315796 for iteration= 894\n",
      "loss= 3.1840860843658447 for iteration= 895\n",
      "loss= 3.094761848449707 for iteration= 896\n",
      "loss= 2.6939468383789062 for iteration= 897\n",
      "loss= 2.5893704891204834 for iteration= 898\n",
      "loss= 2.6654300689697266 for iteration= 899\n",
      "loss= 2.836803436279297 for iteration= 900\n",
      "loss= 2.7765111923217773 for iteration= 901\n",
      "loss= 2.2706620693206787 for iteration= 902\n",
      "loss= 2.646068811416626 for iteration= 903\n",
      "loss= 3.154479503631592 for iteration= 904\n",
      "loss= 3.1927762031555176 for iteration= 905\n",
      "loss= 2.6539969444274902 for iteration= 906\n",
      "loss= 2.963252544403076 for iteration= 907\n",
      "loss= 2.9498302936553955 for iteration= 908\n",
      "loss= 2.998992919921875 for iteration= 909\n",
      "loss= 2.9329447746276855 for iteration= 910\n",
      "loss= 3.012646436691284 for iteration= 911\n",
      "loss= 2.241889715194702 for iteration= 912\n",
      "loss= 2.96966290473938 for iteration= 913\n",
      "loss= 2.4885993003845215 for iteration= 914\n",
      "loss= 2.920809030532837 for iteration= 915\n",
      "loss= 2.9664084911346436 for iteration= 916\n",
      "loss= 2.670999526977539 for iteration= 917\n",
      "loss= 3.102339267730713 for iteration= 918\n",
      "loss= 2.953328847885132 for iteration= 919\n",
      "loss= 2.30045223236084 for iteration= 920\n",
      "loss= 2.8690788745880127 for iteration= 921\n",
      "loss= 3.2148594856262207 for iteration= 922\n",
      "loss= 2.5806450843811035 for iteration= 923\n",
      "loss= 3.037182569503784 for iteration= 924\n",
      "loss= 2.949725866317749 for iteration= 925\n",
      "loss= 2.97406005859375 for iteration= 926\n",
      "loss= 2.518313407897949 for iteration= 927\n",
      "loss= 2.8316593170166016 for iteration= 928\n",
      "loss= 2.488358497619629 for iteration= 929\n",
      "loss= 2.9019997119903564 for iteration= 930\n",
      "loss= 2.9493818283081055 for iteration= 931\n",
      "loss= 2.7331485748291016 for iteration= 932\n",
      "loss= 2.6334753036499023 for iteration= 933\n",
      "loss= 2.6882565021514893 for iteration= 934\n",
      "loss= 2.8455657958984375 for iteration= 935\n",
      "loss= 3.149655818939209 for iteration= 936\n",
      "loss= 2.5123374462127686 for iteration= 937\n",
      "loss= 2.6416757106781006 for iteration= 938\n",
      "loss= 2.686734914779663 for iteration= 939\n",
      "loss= 2.2829909324645996 for iteration= 940\n",
      "loss= 2.3254923820495605 for iteration= 941\n",
      "loss= 2.619614362716675 for iteration= 942\n",
      "loss= 2.5733442306518555 for iteration= 943\n",
      "loss= 2.8204660415649414 for iteration= 944\n",
      "loss= 2.735368013381958 for iteration= 945\n",
      "loss= 2.5956203937530518 for iteration= 946\n",
      "loss= 2.887058734893799 for iteration= 947\n",
      "loss= 2.4886186122894287 for iteration= 948\n",
      "loss= 2.7090227603912354 for iteration= 949\n",
      "loss= 2.3619208335876465 for iteration= 950\n",
      "loss= 2.7572216987609863 for iteration= 951\n",
      "loss= 2.372919797897339 for iteration= 952\n",
      "loss= 2.585928201675415 for iteration= 953\n",
      "loss= 2.5722742080688477 for iteration= 954\n",
      "loss= 2.7274839878082275 for iteration= 955\n",
      "loss= 2.480592966079712 for iteration= 956\n",
      "loss= 2.389287233352661 for iteration= 957\n",
      "loss= 2.6444296836853027 for iteration= 958\n",
      "loss= 2.6428136825561523 for iteration= 959\n",
      "loss= 2.61383056640625 for iteration= 960\n",
      "loss= 2.5155832767486572 for iteration= 961\n",
      "loss= 2.876368284225464 for iteration= 962\n",
      "loss= 2.7377724647521973 for iteration= 963\n",
      "loss= 2.8754138946533203 for iteration= 964\n",
      "loss= 2.951601982116699 for iteration= 965\n",
      "loss= 2.793038845062256 for iteration= 966\n",
      "loss= 3.1031832695007324 for iteration= 967\n",
      "loss= 2.39430570602417 for iteration= 968\n",
      "loss= 2.4206387996673584 for iteration= 969\n",
      "loss= 2.918907642364502 for iteration= 970\n",
      "loss= 3.134110450744629 for iteration= 971\n",
      "loss= 2.7904062271118164 for iteration= 972\n",
      "loss= 3.28592848777771 for iteration= 973\n",
      "loss= 2.4109604358673096 for iteration= 974\n",
      "loss= 2.670339584350586 for iteration= 975\n",
      "loss= 2.7190420627593994 for iteration= 976\n",
      "loss= 2.9633753299713135 for iteration= 977\n",
      "loss= 2.578773260116577 for iteration= 978\n",
      "loss= 2.474175453186035 for iteration= 979\n",
      "loss= 3.1766085624694824 for iteration= 980\n",
      "loss= 2.9556663036346436 for iteration= 981\n",
      "loss= 2.556226968765259 for iteration= 982\n",
      "loss= 2.785984754562378 for iteration= 983\n",
      "loss= 2.257404327392578 for iteration= 984\n",
      "loss= 2.472795009613037 for iteration= 985\n",
      "loss= 2.6285548210144043 for iteration= 986\n",
      "loss= 2.648531675338745 for iteration= 987\n",
      "loss= 3.009507894515991 for iteration= 988\n",
      "loss= 2.6461520195007324 for iteration= 989\n",
      "loss= 2.5078816413879395 for iteration= 990\n",
      "loss= 2.7005274295806885 for iteration= 991\n",
      "loss= 2.7513537406921387 for iteration= 992\n",
      "loss= 2.8928756713867188 for iteration= 993\n",
      "loss= 2.972139596939087 for iteration= 994\n",
      "loss= 3.063124656677246 for iteration= 995\n",
      "loss= 2.507960081100464 for iteration= 996\n",
      "loss= 3.103778839111328 for iteration= 997\n",
      "loss= 2.5926363468170166 for iteration= 998\n",
      "loss= 2.768340587615967 for iteration= 999\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    #creating a minibatch\n",
    "    ix = torch.randint(0,X.shape[0], (32,))\n",
    "    #in the above line of code we are generating 32 random numbers between 0 and the number of examples(X.shape[0])\n",
    "    # forward pass\n",
    "    emb = C[X[ix]] #the shape is (32,3,2)\n",
    "    # in the code above we are only selecting 32 examples with the index ix randomly and calculating the loss based on those examples\n",
    "    #and the implemeting gradient based on that loss this will speed up the training\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) #we are using tanh activation fn so the numbers in h will be -1 and 1 \n",
    "    # We pass -1 to emb.view(), becuase we want pytorch to guess what what will be the right number for rows given we have already told it the number of columns are 6\n",
    "    # here you can also use emb.reshape(32,6) the difference is emb.view() will not use extra space it ensure that the emb tensor and and the new tensor that we create will use the same data so no memory wastag\n",
    "    logits = h @ W2 + b2 #the shape is 32,27\n",
    "    # implementing the loss function\n",
    "    loss = F.cross_entropy(logits, Y[ix])  #implementing the categorical cross entropy using pytorch\n",
    "    print(f'loss= {loss.item()} for iteration= {i}') \n",
    "    #we use pytorch here because large positive numbers when exponentiated causes the overflow which can be handled by subtracting the biggest number in the logits from each element row wise, and pytorch handles this operation internally\n",
    "\n",
    "    # Implementing backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    # param update\n",
    "    for p in parameters:\n",
    "        p.data -= 0.1 * p.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
